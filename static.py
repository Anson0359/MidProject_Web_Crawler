# å®‰è£å¥—ä»¶
#pip install requests beautifulsoup4
import requests
from bs4 import BeautifulSoup
import pandas as pd

url = "https://www.yzu.edu.tw/index.php/tw/news-tw/msg-tw"
headers = {
    "User-Agent": "Mozilla/5.0"
}

response = requests.get(url, headers=headers)
response.encoding = "utf-8"  # ç¢ºä¿ä¸­æ–‡é¡¯ç¤ºæ­£å¸¸

# ç¯©é¸æ‰€éœ€è³‡æ–™
soup = BeautifulSoup(response.text, "html.parser")
content = soup.find('div',class_="com-content-article__body")
datas = content.find_all('a')

#from google.colab import files
news_data = []
for data in datas:
    data_text = data.get_text()
    link = data['href']
    news_data.append([data_text,link])

# å­˜å…¥ DataFrame
df = pd.DataFrame(news_data, columns=['æ¨™é¡Œ', 'éˆçµ'])

print(f"\nâœ… æˆåŠŸå–å¾— {len(df)} å…¬å‘Šçš„è³‡æ–™")

# --- Step 4: å¯«å…¥ CSV ä¸¦æä¾›ä¸‹è¼‰ ---
csv_filename = 'static.csv'
df.to_csv(csv_filename, index=False, encoding='utf-8-sig')
print(f"\nğŸ“ è³‡æ–™å·²å¯«å…¥ CSV æª”æ¡ˆï¼š{csv_filename}")

# æä¾›ä¸‹è¼‰é€£çµ
#files.download(csv_filename)